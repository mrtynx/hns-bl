{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available? True\n",
      "Number of available devices: 1\n",
      "Index of current device: 0\n",
      "Device name: NVIDIA GeForce GTX 1650 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is GPU available? {torch.cuda.is_available()}\")\n",
    "print(f\"Number of available devices: {torch.cuda.device_count()}\")\n",
    "print(f\"Index of current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "#defaults\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nacitanie dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'images', 'labels'])\n",
      "(28, 28, 18724)\n",
      "(18724, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class notMNIST(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.images = data\n",
    "        self.labels = labels\n",
    "\n",
    "        self.transformation = transforms.Compose([\n",
    "                                                  \n",
    "            transforms.ToTensor(),\n",
    "            transforms.ConvertImageDtype(dtype=torch.float32),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        img_tensor = self.transformation(img)\n",
    "        y_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return img_tensor.view(1, 28, 28), y_tensor\n",
    "\n",
    "\n",
    "data = loadmat('notMNIST_small.mat')\n",
    "print(data.keys())\n",
    "\n",
    "images = data['images']\n",
    "labels = data['labels']\n",
    "\n",
    "print(images.shape)\n",
    "images = [images[:, :, i] for i in range(0, images.shape[2])]\n",
    "images = np.asarray(images)\n",
    "print(images.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.4, shuffle=True)\n",
    "\n",
    "train_dataset = notMNIST(x_train, y_train)\n",
    "test_dataset = notMNIST(x_test, y_test)\n",
    "\n",
    "trainloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import sieti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook notMNIST_networks.ipynb to python\n",
      "[NbConvertApp] Writing 1921 bytes to notMNIST_networks.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python notMNIST_networks.ipynb\n",
    "\n",
    "#The classes cannot be run from a jupyter notebook, this executes the script and converts it to a python script\n",
    "\n",
    "from notMNIST_networks import MLP, CustomCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenovacia funkcia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_function(model, trainloader, writer, batch_size, n_epochs, learning_rate):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    acc_history = []\n",
    "    loss_history = []\n",
    "    final_labels = []\n",
    "    final_predicted = []\n",
    "\n",
    "    for epoch in trange(1, n_epochs + 1, desc=\"1st loop\"):\n",
    "        epoch_loss = 0\n",
    "        n_batches = len(train_dataset) // batch_size\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        accuracy_train = 0\n",
    "\n",
    "        for step, (images, labels) in enumerate(tqdm(trainloader, desc=\"Epoch {}/{}\".format(epoch, N_EPOCHS))):\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Dopredne sirenie, \n",
    "            # ziskame pravdepodobnosti tried tym, ze posleme do modelu vstupy\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Vypocitame chybu algoritmu       \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Uspesnost algoritmu\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy_train = correct / total\n",
    "            epoch_loss += loss.item() \n",
    "            \n",
    "            # Je vhodne zavolat zero_grad() pred zavolanim spatneho sirenia \n",
    "            # pre vynulovanie gradientov z predosleho volania loss.backward()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Spatne sirenie chyby, vypocitaju sa gradienty\n",
    "            loss.backward()\n",
    "            \n",
    "            # Aktualizacia vah pomocou optimalizatora\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % n_batches == 0 and step != 0:\n",
    "                epoch_loss = epoch_loss / n_batches\n",
    "\n",
    "                writer.add_scalar(\n",
    "                    'training loss',\n",
    "                    epoch_loss,\n",
    "                    epoch\n",
    "                )\n",
    "                \n",
    "                writer.add_scalar(\n",
    "                    'training accuracy',\n",
    "                    accuracy_train,\n",
    "                    epoch\n",
    "                )\n",
    "\n",
    "                acc_history.append(accuracy_train)\n",
    "                loss_history.append(epoch_loss)\n",
    "                print(\"Epoch {}, Loss {:.6f}, Accuracy {:.2f}% \".format(epoch, epoch_loss, accuracy_train * 100))\n",
    "                epoch_loss = 0\n",
    "\n",
    "                #to display knovolution kernels/filters?\n",
    "                #print(model.layer1[0].conv1.weight[0][0])\n",
    "                #print(model.layer2[0].conv1.weight[0][0])\n",
    "                #print(model.layer3[0].conv1.weight[0][0])\n",
    "\n",
    "            final_predicted += predicted.tolist()\n",
    "            final_labels += labels.tolist()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            #writing training data\n",
    "            \n",
    "    writer.add_hparams(\n",
    "        {\n",
    "        'optimizer': optimizer.__class__.__name__,\n",
    "        'lr': LEARNING_RATE, \n",
    "        'batch_size': BATCH_SIZE\n",
    "        },\n",
    "        {\n",
    "        'hparam/train/accuracy': accuracy_train,\n",
    "        }\n",
    "    )\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenovanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d702bf008b3425f9a6185fd40b34948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1st loop:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5609c38f534ece90678246fab2dfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 2.308039, Accuracy 17.89% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d78c06f0037438aacc716d4b5bd2ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 2.309930, Accuracy 17.72% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dca472841b447db90732126884a4838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 2.277902, Accuracy 20.90% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc3c8f9371646b8bc3d5df3d509782a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 2.269029, Accuracy 21.76% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e462a42e5f34f819d03de74ab155bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 2.299614, Accuracy 18.77% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110e91be445b49fbad56fefb2f8d1719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 2.333160, Accuracy 15.44% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d959459e0744aaa2a84b5467d2ada7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 2.336183, Accuracy 15.14% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917881b4bcda4accb0c34c6082b0fed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 2.324545, Accuracy 16.29% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8b450286c7405caaa2a8d00ff048a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 2.328783, Accuracy 15.89% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3cdf1bed3e4d2ab42fe6137bcd43cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 2.311205, Accuracy 17.62% \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_cnn_1 = CustomCNN()\n",
    "\n",
    "model_mlp = MLP()\n",
    "writer_mlp = SummaryWriter('./runs/experiment_MLP')\n",
    "\n",
    "training_function(model_mlp,trainloader,writer_mlp,BATCH_SIZE,N_EPOCHS,LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = CustomCNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ukladanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MLP = \"./model_mlp.pt\"\n",
    "PATH_CNN_1= \"./model_cnn_1.pt\"\n",
    "PATH_CNN_2= \"./model_cnn_2.pt\"\n",
    "PATH_CNN_resnet= \"./model_cnn_resnet.pt\"\n",
    "\n",
    "#saving MLP\n",
    "torch.save(model_mlp.state_dict(), PATH_MLP)\n",
    "\n",
    "#torch.save(model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
